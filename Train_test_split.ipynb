{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_split\n",
    "We want to withhold a subset of the data to estimate the performance of the final chosen model at the end. Therefore, we currently exclude 20% of the data from any analyses. All training, validation, and model comparison will be completed on the remaining 80% of the data.  \n",
    " \n",
    "Since the full asylum version is a subset of any asylum version, we create the split on the full asylum version, save the list of train and test cases,so that we can use this list to split the data for subsequent analyses.\n",
    "this code only needs to be run one time--once we've done it, we can load the train and test cases from the file where they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "pd.set_option('precision', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN CLEANED DATASET\n",
    "path = '/home/emilyboeke/'\n",
    "master_app = pd.read_csv(path + 'merged_any_master_app.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(master_app,  test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "188\n",
      "371\n",
      "371\n",
      "188\n"
     ]
    }
   ],
   "source": [
    "#check that all judges and nationalities are present in both training and test sets.\n",
    "print(len(X_train.nat.unique()))\n",
    "print(len(X_test.nat.unique()))\n",
    "print(len(X_train.tracid.unique()))\n",
    "print(len(X_test.tracid.unique()))\n",
    "print(len(np.intersect1d(X_test.nat.unique(),X_train.nat.unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list of train and test idncases.\n",
    "train_cases = X_train.idncase\n",
    "test_cases = X_test.idncase\n",
    "train_cases.to_csv(path+'train_cases_any_asylum.csv',index=False)\n",
    "test_cases.to_csv(path+'test_cases_any_asylum.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
