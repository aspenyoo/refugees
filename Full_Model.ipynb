{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import CategoricalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Test/Train Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('../merged_any_master_schedule.csv')\n",
    "test_cases = pd.read_csv('../test_cases_any_asylum_full_model.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = test_cases.rename(columns={0:'num'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = file[~file.idncase.isin(test_cases.num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = file[file.idncase.isin(test_cases.num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cleaning(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.drop(columns=['idncase', 'idnproceeding', 'adj_date', 'adj_time_start2', 'adj_time_stop2', 'osc_date_y'])\n",
    "        X.loc[(X[\"dec\"] == 'DENY'),'dec'] = 0\n",
    "        X.loc[(X[\"dec\"] == 'GRANT'),'dec'] = 1\n",
    "        X['comp_date'] = pd.to_datetime(X['comp_date'],infer_datetime_format = True)\n",
    "        startdate = np.datetime64('1984-07-11')\n",
    "        X['comp_date_in_days'] = X['comp_date'].apply(lambda x: (x - startdate).days)\n",
    "        X = X.drop(columns=['comp_date'], axis=1)\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = Cleaning()\n",
    "train_data = clean.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['dec']\n",
    "X_train = train_data.drop(columns=['dec'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        num_frame = X.select_dtypes(include=[self.dtype])\n",
    "        self.names = num_frame.columns\n",
    "        return num_frame\n",
    "    def get_feature_names(self):\n",
    "        return self.names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        names = []\n",
    "        for col in X.columns:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "            #cat_frame = X.apply(le.fit_transform)\n",
    "            names.extend(le.classes_)\n",
    "        self.names = names\n",
    "        return X\n",
    "    def get_feature_names(self):\n",
    "        return self.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('selector', Selector(np.number)),\n",
    "        ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', Selector('object')),\n",
    "        ('labeler', CustomLabelEncoder()),\n",
    "        ('encoder', OneHotEncoder()),\n",
    "]) \n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[ \n",
    "        ('numerical', num_pipeline),  \n",
    "        ('categorical', cat_pipeline)   \n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tr= full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Grid Search On Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1','l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_tr, y_train)\n",
    "result = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        2.373631         0.013899         0.643052          0.726646   0.001   \n",
      "1        2.424796         0.019857         0.669493          0.765314   0.001   \n",
      "2       10.345317         0.032659         0.680687          0.776167    0.01   \n",
      "3        4.903254         0.017303         0.694461          0.786889    0.01   \n",
      "4       53.518398         0.022968         0.702331          0.792865     0.1   \n",
      "5        9.248451         0.018657         0.704239          0.794846     0.1   \n",
      "6      100.118109         0.015562         0.704828          0.796316       1   \n",
      "7       21.231059         0.014013         0.704770          0.796598       1   \n",
      "8       97.647666         0.013785         0.703872          0.796872      10   \n",
      "9       41.358622         0.021417         0.703997          0.796837      10   \n",
      "10      20.346499         0.018359         0.703046          0.796869     100   \n",
      "11      51.879921         0.011552         0.703447          0.796867     100   \n",
      "12      12.985975         0.018247         0.703036          0.796864    1000   \n",
      "13      63.449292         0.007964         0.703447          0.796867    1000   \n",
      "\n",
      "   param_penalty                         params  rank_test_score  \\\n",
      "0             l1  {'C': 0.001, 'penalty': 'l1'}               14   \n",
      "1             l2  {'C': 0.001, 'penalty': 'l2'}               13   \n",
      "2             l1   {'C': 0.01, 'penalty': 'l1'}               12   \n",
      "3             l2   {'C': 0.01, 'penalty': 'l2'}               11   \n",
      "4             l1    {'C': 0.1, 'penalty': 'l1'}               10   \n",
      "5             l2    {'C': 0.1, 'penalty': 'l2'}                3   \n",
      "6             l1      {'C': 1, 'penalty': 'l1'}                1   \n",
      "7             l2      {'C': 1, 'penalty': 'l2'}                2   \n",
      "8             l1     {'C': 10, 'penalty': 'l1'}                5   \n",
      "9             l2     {'C': 10, 'penalty': 'l2'}                4   \n",
      "10            l1    {'C': 100, 'penalty': 'l1'}                8   \n",
      "11            l2    {'C': 100, 'penalty': 'l2'}                6   \n",
      "12            l1   {'C': 1000, 'penalty': 'l1'}                9   \n",
      "13            l2   {'C': 1000, 'penalty': 'l2'}                6   \n",
      "\n",
      "    split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
      "0            0.578830            0.743793       ...                  0.648767   \n",
      "1            0.596005            0.782951       ...                  0.643042   \n",
      "2            0.597744            0.793126       ...                  0.657197   \n",
      "3            0.599676            0.803779       ...                  0.677175   \n",
      "4            0.600256            0.810024       ...                  0.690098   \n",
      "5            0.601343            0.811998       ...                  0.689180   \n",
      "6            0.600039            0.813418       ...                  0.689205   \n",
      "7            0.600304            0.813877       ...                  0.689349   \n",
      "8            0.600111            0.814124       ...                  0.689011   \n",
      "9            0.600087            0.814021       ...                  0.689205   \n",
      "10           0.600304            0.814142       ...                  0.689011   \n",
      "11           0.600039            0.814124       ...                  0.689060   \n",
      "12           0.600546            0.814160       ...                  0.688963   \n",
      "13           0.600353            0.814112       ...                  0.689035   \n",
      "\n",
      "    split2_train_score  split3_test_score  split3_train_score  \\\n",
      "0             0.728457           0.691137            0.716675   \n",
      "1             0.768031           0.749499            0.758984   \n",
      "2             0.779801           0.761963            0.769649   \n",
      "3             0.792277           0.764814            0.779746   \n",
      "4             0.799331           0.767978            0.785683   \n",
      "5             0.801330           0.768389            0.787652   \n",
      "6             0.802997           0.767012            0.789161   \n",
      "7             0.803196           0.767230            0.789210   \n",
      "8             0.803516           0.765973            0.789524   \n",
      "9             0.803474           0.766022            0.789542   \n",
      "10            0.803443           0.765442            0.789548   \n",
      "11            0.803492           0.765563            0.789542   \n",
      "12            0.803474           0.765369            0.789518   \n",
      "13            0.803474           0.765418            0.789554   \n",
      "\n",
      "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
      "0            0.721381            0.712877      1.301111        0.001366   \n",
      "1            0.746286            0.751913      0.139450        0.010119   \n",
      "2            0.736503            0.762499      3.929177        0.027449   \n",
      "3            0.772351            0.771896      0.660963        0.004592   \n",
      "4            0.785902            0.776636     39.271053        0.009386   \n",
      "5            0.793946            0.778412      1.194199        0.006812   \n",
      "6            0.798754            0.779445     24.876109        0.000474   \n",
      "7            0.798391            0.779698      2.657546        0.001554   \n",
      "8            0.795154            0.779910     17.634962        0.003252   \n",
      "9            0.795444            0.779873      2.705105        0.007757   \n",
      "10           0.791241            0.779885     19.814247        0.006704   \n",
      "11           0.793318            0.779879      3.266144        0.003909   \n",
      "12           0.791144            0.779903      6.225239        0.004292   \n",
      "13           0.793149            0.779885      2.560239        0.001305   \n",
      "\n",
      "    std_test_score  std_train_score  \n",
      "0         0.058678         0.011038  \n",
      "1         0.065773         0.010378  \n",
      "2         0.060154         0.010298  \n",
      "3         0.065738         0.010864  \n",
      "4         0.067943         0.011412  \n",
      "5         0.069665         0.011472  \n",
      "6         0.070976         0.011602  \n",
      "7         0.070890         0.011683  \n",
      "8         0.069835         0.011693  \n",
      "9         0.069906         0.011666  \n",
      "10        0.068655         0.011695  \n",
      "11        0.069289         0.011697  \n",
      "12        0.068554         0.011702  \n",
      "13        0.069124         0.011688  \n",
      "\n",
      "[14 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "feature_weight = np.abs(grid_search.best_estimator_.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-cfcbcbdd5ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'feature_names'"
     ]
    }
   ],
   "source": [
    "final_model.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = clean.transform(test)\n",
    "y_test = test_data['dec']\n",
    "X_test = test_data.drop(columns=['dec'], axis=1)\n",
    "X_test_tr = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_features = num_pipeline.named_steps['selector'].get_feature_names()\n",
    "#cat_features = cat_pipeline.named_steps['labeler'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.696774692252691\n"
     ]
    }
   ],
   "source": [
    "print(final_model.score(X_test_tr, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Grid Search On Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\"max_depth\": [3, None],\n",
    "        \"max_features\": randint(1, 10),\n",
    "        \"min_samples_leaf\": randint(1, 10),\n",
    "        \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.905043         0.198299         0.634790          0.690383   \n",
      "1       0.450950         0.051113         0.520861          0.520876   \n",
      "2       0.445638         0.057486         0.525204          0.540857   \n",
      "3       0.754962         0.107842         0.576995          0.640315   \n",
      "4       0.429582         0.068765         0.520272          0.521501   \n",
      "5       0.446517         0.073850         0.522494          0.530022   \n",
      "6       0.418423         0.056192         0.520634          0.521245   \n",
      "7       0.587739         0.097633         0.630442          0.683123   \n",
      "8       0.961293         0.121219         0.590372          0.688161   \n",
      "9       0.392032         0.060565         0.526538          0.527558   \n",
      "\n",
      "  param_criterion param_max_depth param_max_features param_min_samples_leaf  \\\n",
      "0         entropy            None                  9                      4   \n",
      "1         entropy               3                  1                      3   \n",
      "2            gini               3                  7                      4   \n",
      "3            gini            None                  5                      2   \n",
      "4            gini               3                  4                      3   \n",
      "5         entropy            None                  2                      8   \n",
      "6         entropy               3                  2                      5   \n",
      "7         entropy            None                  9                      8   \n",
      "8            gini            None                  6                      2   \n",
      "9            gini               3                  1                      3   \n",
      "\n",
      "                                              params  rank_test_score  \\\n",
      "0  {'criterion': 'entropy', 'max_depth': None, 'm...                1   \n",
      "1  {'criterion': 'entropy', 'max_depth': 3, 'max_...                8   \n",
      "2  {'criterion': 'gini', 'max_depth': 3, 'max_fea...                6   \n",
      "3  {'criterion': 'gini', 'max_depth': None, 'max_...                4   \n",
      "4  {'criterion': 'gini', 'max_depth': 3, 'max_fea...               10   \n",
      "5  {'criterion': 'entropy', 'max_depth': None, 'm...                7   \n",
      "6  {'criterion': 'entropy', 'max_depth': 3, 'max_...                9   \n",
      "7  {'criterion': 'entropy', 'max_depth': None, 'm...                2   \n",
      "8  {'criterion': 'gini', 'max_depth': None, 'max_...                3   \n",
      "9  {'criterion': 'gini', 'max_depth': 3, 'max_fea...                5   \n",
      "\n",
      "        ...         split2_test_score  split2_train_score  split3_test_score  \\\n",
      "0       ...                  0.636785            0.694609           0.622509   \n",
      "1       ...                  0.520859            0.520880           0.520859   \n",
      "2       ...                  0.544484            0.619786           0.520859   \n",
      "3       ...                  0.546706            0.694989           0.542406   \n",
      "4       ...                  0.519941            0.521677           0.521270   \n",
      "5       ...                  0.520255            0.529830           0.526439   \n",
      "6       ...                  0.520787            0.521188           0.521342   \n",
      "7       ...                  0.662922            0.683775           0.687489   \n",
      "8       ...                  0.469092            0.684898           0.632244   \n",
      "9       ...                  0.520859            0.520862           0.535087   \n",
      "\n",
      "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
      "0            0.686444           0.745223            0.688691      0.255252   \n",
      "1            0.520880           0.520859            0.520862      0.080772   \n",
      "2            0.520874           0.520859            0.520862      0.050998   \n",
      "3            0.549203           0.653357            0.664426      0.274592   \n",
      "4            0.521073           0.521197            0.521339      0.070117   \n",
      "5            0.524352           0.528420            0.523797      0.094495   \n",
      "6            0.521097           0.520907            0.520946      0.105576   \n",
      "7            0.674324           0.670822            0.669288      0.077765   \n",
      "8            0.675852           0.663236            0.675900      0.139460   \n",
      "9            0.530832           0.520859            0.520862      0.165422   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.039022        0.059525         0.002743  \n",
      "1        0.020949        0.000005         0.000007  \n",
      "2        0.013778        0.009668         0.039466  \n",
      "3        0.045898        0.048141         0.051937  \n",
      "4        0.021390        0.000931         0.000264  \n",
      "5        0.060425        0.004166         0.006482  \n",
      "6        0.025615        0.000712         0.000220  \n",
      "7        0.037896        0.058008         0.010274  \n",
      "8        0.042326        0.067908         0.013637  \n",
      "9        0.027462        0.005882         0.005542  \n",
      "\n",
      "[10 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "dec_tree = DecisionTreeClassifier()\n",
    "grid_search_dt = RandomizedSearchCV(dec_tree, param_grid_dt, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_dt.fit(X_train_tr, y_train)\n",
    "result = pd.DataFrame(grid_search_dt.cv_results_)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_features': [2, 4, 6, 8, 10],\n",
    "    'bootstrap': [False, True],\n",
    "    'max_depth':[1, 2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       4.311742         0.642632         0.520866          0.520969   \n",
      "1      17.631970         1.759429         0.574062          0.645420   \n",
      "2      20.806815         3.863836         0.529359          0.522397   \n",
      "3      38.603262         4.097031         0.585058          0.667455   \n",
      "4       4.603935         0.833271         0.520866          0.520866   \n",
      "5       7.582596         0.902206         0.539572          0.538654   \n",
      "6       9.046582         1.063145         0.573400          0.625021   \n",
      "7       7.293392         1.063364         0.563873          0.612716   \n",
      "8      27.285051         2.804135         0.570444          0.646634   \n",
      "9      18.579701         1.360250         0.615466          0.685966   \n",
      "\n",
      "  param_bootstrap param_max_depth param_max_features param_n_estimators  \\\n",
      "0            True               1                  4                100   \n",
      "1           False               4                  6                300   \n",
      "2           False               2                  4                500   \n",
      "3            True               4                  8                500   \n",
      "4           False               1                  2                100   \n",
      "5           False               5                  2                100   \n",
      "6            True               4                  6                100   \n",
      "7           False               3                  8                100   \n",
      "8            True               3                 10                500   \n",
      "9           False               5                  8                300   \n",
      "\n",
      "                                              params  rank_test_score  \\\n",
      "0  {'n_estimators': 100, 'max_features': 4, 'max_...                9   \n",
      "1  {'n_estimators': 300, 'max_features': 6, 'max_...                3   \n",
      "2  {'n_estimators': 500, 'max_features': 4, 'max_...                8   \n",
      "3  {'n_estimators': 500, 'max_features': 8, 'max_...                2   \n",
      "4  {'n_estimators': 100, 'max_features': 2, 'max_...                9   \n",
      "5  {'n_estimators': 100, 'max_features': 2, 'max_...                7   \n",
      "6  {'n_estimators': 100, 'max_features': 6, 'max_...                4   \n",
      "7  {'n_estimators': 100, 'max_features': 8, 'max_...                6   \n",
      "8  {'n_estimators': 500, 'max_features': 10, 'max...                5   \n",
      "9  {'n_estimators': 300, 'max_features': 8, 'max_...                1   \n",
      "\n",
      "        ...         split2_test_score  split2_train_score  split3_test_score  \\\n",
      "0       ...                  0.520859            0.520862           0.520883   \n",
      "1       ...                  0.554388            0.656594           0.541489   \n",
      "2       ...                  0.520883            0.521194           0.520859   \n",
      "3       ...                  0.575549            0.681106           0.577675   \n",
      "4       ...                  0.520883            0.520886           0.520859   \n",
      "5       ...                  0.527140            0.542747           0.522429   \n",
      "6       ...                  0.549049            0.621586           0.562311   \n",
      "7       ...                  0.565862            0.632728           0.562070   \n",
      "8       ...                  0.554388            0.656727           0.556755   \n",
      "9       ...                  0.582240            0.693268           0.637896   \n",
      "\n",
      "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
      "0            0.521399           0.520859            0.520862      0.321223   \n",
      "1            0.623766           0.528468            0.628500      1.735265   \n",
      "2            0.521466           0.520859            0.521176      1.362824   \n",
      "3            0.641901           0.528951            0.623379      2.893544   \n",
      "4            0.520862           0.520859            0.520862      0.954108   \n",
      "5            0.532384           0.521028            0.539160      0.647941   \n",
      "6            0.626139           0.522985            0.585201      0.791690   \n",
      "7            0.601065           0.521608            0.583830      1.479726   \n",
      "8            0.625517           0.526391            0.610987      1.037178   \n",
      "9            0.677011           0.613136            0.660597      1.199904   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.071920        0.000010         0.000215  \n",
      "1        0.439791        0.050909         0.015925  \n",
      "2        0.346836        0.016610         0.001637  \n",
      "3        0.846854        0.065207         0.030305  \n",
      "4        0.149003        0.000010         0.000010  \n",
      "5        0.177321        0.028119         0.004423  \n",
      "6        0.114879        0.063676         0.022682  \n",
      "7        0.246770        0.034576         0.017870  \n",
      "8        0.302968        0.052410         0.024676  \n",
      "9        0.341447        0.058319         0.015122  \n",
      "\n",
      "[10 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "grid_search_rf = RandomizedSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_rf.fit(X_train_tr, y_train)\n",
    "result = pd.DataFrame(grid_search_rf.cv_results_)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Random Forest Classifier on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6195914739018688\n"
     ]
    }
   ],
   "source": [
    "final_model_rf = grid_search_rf.best_estimator_\n",
    "print(final_model_rf.score(X_test_tr, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349\n"
     ]
    }
   ],
   "source": [
    "feature_weight_rf = grid_search_rf.best_estimator_.feature_importances_\n",
    "#print(len(feature_weight_rf))\n",
    "#num_features = num_pipeline.named_steps['selector'].get_feature_names()\n",
    "cat_features = list(cat_pipeline.named_steps['encoder'].categories_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
