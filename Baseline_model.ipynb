{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "pd.set_option('precision', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned dataset\n",
    "path = '/home/emilyboeke/'\n",
    "master_app = pd.read_csv(path + 'merged2_master_app.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forgot to output excluding the auto-generated index column.... so now I'm dropping it. Can be optimized later\n",
    "master_app = master_app.drop(master_app.columns[0], axis=1)\n",
    "\n",
    "# drop NaNs. drops to 597954 obs\n",
    "#tracid            598132\n",
    "#nat               614012\n",
    "#(other variables have 614204 observations)\n",
    "#master_app = master_app.dropna()\n",
    "\n",
    "# change dec to binary number, so we can do summary stats on it\n",
    "master_app.loc[(master_app[\"dec\"] == 'DENY'),'dec'] = 0\n",
    "master_app.loc[(master_app[\"dec\"] == 'GRANT'),'dec'] = 1\n",
    "\n",
    "# delete NTA dates before 1984. nObs = \n",
    "master_app['osc_date'] = pd.to_datetime(master_app['osc_date'],infer_datetime_format = True)\n",
    "master_app = master_app[master_app.osc_date.dt.year>1984]\n",
    "\n",
    "#master_app.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# selecting relevant features and target variable.\n",
    "df = master_app[['osc_date', 'tracid', 'nat', 'dec']]\n",
    "\n",
    "#print(df.head(10))\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE OSC_DATE TO CONTINUOUS NUMBER.\n",
    "\n",
    "osc_date_cont = []\n",
    "startdate = np.datetime64('1984-01-01') # earliest date. from which timedelta is calculated\n",
    "\n",
    "# change osc_date to continuous number\n",
    "for i in df.index:\n",
    "    x = df.loc[i,'osc_date'] - startdate\n",
    "    osc_date_cont.append(x.days)\n",
    "    \n",
    "osc_date_cont = np.array(osc_date_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 403, 631])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE HOT ENCODE CATEGORICAL VARIABLES\n",
    "\n",
    "# change string nationalities to integer categories\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "le = LabelEncoder()\n",
    "nat_int = le.fit_transform(df['nat'])\n",
    "nat_int = np.reshape(nat_int,[len(nat_int),1])\n",
    "\n",
    "# get N x 2 array of features\n",
    "feat_int = np.concatenate((df[['tracid']], nat_int), axis=1)\n",
    "feat_int.shape\n",
    "\n",
    "# get one hot encoder of features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(feat_int)  \n",
    "enc.feature_indices_\n",
    "\n",
    "# create sparse matrix of all observations in Compressed Sparse Row format\n",
    "blah = enc.transform(feat_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATENATING ONE HOT ENCODED FEATURES WITH CONTINUOUS FEATURES\n",
    "\n",
    "# changes csr to csc, bc simpler to work with columns than rows\n",
    "blah = scipy.sparse.csr_matrix.tocsc(blah)\n",
    "\n",
    "# concatenating relevant fields\n",
    "new_data = np.concatenate((blah.data, osc_date_cont)) # non-zero values in matrix\n",
    "new_indices = np.concatenate((blah.indices, range(len(osc_date_cont)))) # row indices for each column\n",
    "new_ind_ptr = np.append(blah.indptr, blah.indptr[-1]+len(osc_date_cont))\n",
    "\n",
    "# making new matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "final_feature_mat = csc_matrix((new_data, new_indices, new_ind_ptr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting into train, validation, and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE LAST 20% OF DATA AND DO NOT TOUCH IT!\n",
    "\n",
    "# random seed\n",
    "\n",
    "# shuffle data\n",
    "\n",
    "idx = round(feat_int.shape[0] * .8)\n",
    "X = feat_int[0:idx]\n",
    "y = df['dec'][0:idx]\n",
    "\n",
    "X_test_donttouch = feat_int[idx:-1]\n",
    "y_test_donttouch = df['dec'][idx:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementing logistic regression with ridge penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten-fold cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
