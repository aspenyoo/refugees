{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "pd.set_option('precision', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN CLEANED DATASET\n",
    "\n",
    "path = '/home/emilyboeke/'\n",
    "master_app = pd.read_csv(path + 'merged2_master_app.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIONAL LAST MINUTE DATA CLEANING\n",
    "\n",
    "# forgot to output excluding the auto-generated index column.... so now I'm dropping it. Can be optimized later\n",
    "master_app = master_app.drop(master_app.columns[0], axis=1)\n",
    "\n",
    "# change dec to binary number, so we can do summary stats on it\n",
    "master_app.loc[(master_app[\"dec\"] == 'DENY'),'dec'] = 0\n",
    "master_app.loc[(master_app[\"dec\"] == 'GRANT'),'dec'] = 1\n",
    "\n",
    "# delete NTA dates before 1984. \n",
    "master_app['osc_date'] = pd.to_datetime(master_app['osc_date'],infer_datetime_format = True)\n",
    "master_app = master_app[master_app.osc_date.dt.year>1984]\n",
    "\n",
    "#master_app.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# selecting relevant features and target variable.\n",
    "df = master_app[['osc_date', 'tracid', 'nat', 'dec']]\n",
    "df.shape\n",
    "\n",
    "#print(df.head(10))\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE OSC_DATE TO CONTINUOUS NUMBER.\n",
    "\n",
    "osc_date_cont = []\n",
    "startdate = np.datetime64('1984-01-01') # earliest date. from which timedelta is calculated\n",
    "\n",
    "# change osc_date to continuous number\n",
    "for i in df.index:\n",
    "    x = df.loc[i,'osc_date'] - startdate\n",
    "    osc_date_cont.append(x.days)\n",
    "    \n",
    "osc_date_cont = np.array(osc_date_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODE CATEGORICAL VARIABLES\n",
    "\n",
    "# change string nationalities to integer categories \n",
    "le = LabelEncoder()\n",
    "nat_int = le.fit_transform(df['nat'])\n",
    "nat_int = np.reshape(nat_int,[len(nat_int),1])\n",
    "\n",
    "# get N x 2 array of features of interest\n",
    "feat_int = np.concatenate((df[['tracid']], nat_int), axis=1)\n",
    "feat_int.shape\n",
    "\n",
    "# get one hot encoder of features\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(feat_int)  \n",
    "enc.feature_indices_\n",
    "\n",
    "# create sparse matrix of all observations in Compressed Sparse Row format\n",
    "blah = enc.transform(feat_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATENATE ONE HOT ENCODED FEATURES WITH CONTINUOUS FEATURE\n",
    "\n",
    "# changes csr to csc, bc simpler to work with columns than rows\n",
    "blah = scipy.sparse.csr_matrix.tocsc(blah)\n",
    "\n",
    "# concatenating relevant fields\n",
    "new_data = np.concatenate((blah.data, osc_date_cont)) # non-zero values in matrix\n",
    "new_indices = np.concatenate((blah.indices, range(len(osc_date_cont)))) # row indices for each column\n",
    "new_ind_ptr = np.append(blah.indptr, blah.indptr[-1]+len(osc_date_cont))\n",
    "\n",
    "# making new matrix\n",
    "final_feature_mat = csc_matrix((new_data, new_indices, new_ind_ptr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting into train, validation, and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set random seed + shuffle data\n",
    "np.random.seed(0)\n",
    "# !! NEED TO PUT IN SHUFFLING CODE !!\n",
    "\n",
    "# take out last 20% for test\n",
    "idx = round(final_feature_mat.shape[0] * .8)\n",
    "X_test_donttouch = final_feature_mat[idx:]\n",
    "y_test_donttouch = df['dec'][idx:]\n",
    "\n",
    "# define rest of data that we will be fitting/validating\n",
    "X = final_feature_mat[0:idx]\n",
    "y = df['dec'][0:idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementing logistic regression with ridge penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68765487 0.67325328 0.71465786 0.67490522 0.68475337 0.7080227\n",
      " 0.70217723 0.71973484 0.73701154 0.74605528]\n",
      "0.7048226191168687\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
